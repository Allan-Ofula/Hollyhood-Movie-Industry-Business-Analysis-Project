








# Your code here - remember to use markdown cells for comments as well!

import zipfile
import pandas as pd
import numpy as np
import sqlite3
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
import warnings
warnings.filterwarnings("ignore")
import statsmodels.api as sm


# Loading dataset

db_path = "im.db"
conn = sqlite3.connect(db_path)
cursor = conn.cursor()

cursor.execute("SELECT type, name FROM sqlite_master;")
objects = cursor.fetchall()

print("Database objects:", objects)



# Checking  sample of the dataset
df_movies = pd.read_sql("SELECT * FROM movie_basics LIMIT 5;", conn)
print(df_movies)


df_movies.describe()


# Loading CSV files
df_box_office = pd.read_csv("bom.movie_gross.csv")
df_tmdb_movies = pd.read_csv("tmdb.movies.csv")
df_movie_budgets = pd.read_csv("tn.movie_budgets.csv")

# Displaying first few rows
print("Box Office Data:")
display(df_box_office.head())

print("TMDB Movies Data:")
display(df_tmdb_movies.head())

print("Movie Budgets Data:")
display(df_movie_budgets.head())


print("Box Office Data:")
display(df_box_office.describe())

print("TMDB Movies Data:")
display(df_tmdb_movies.describe())

print("Movie Budgets Data:")
display(df_movie_budgets.describe())





# Loading TSV files 
df_movie_info = pd.read_csv("rt.movie_info.tsv", sep="\t", encoding="latin1")
df_reviews = pd.read_csv("rt.reviews.tsv", sep="\t", encoding="latin1")


# Displaying first few rows
print("Movie Info Data:")
display(df_movie_info.head())

print("Reviews Data:")
display(df_reviews.head())





# Checking missing values
def check_missing_values(df, name):
    print(f"\n🔍 Missing values in {name}:")
    missing_values = df.isnull().sum()
    print(missing_values[missing_values > 0])  # Show only columns with missing values

# Check for missing values
check_missing_values(df_box_office, "Box Office Data")
check_missing_values(df_tmdb_movies, "TMDb Movies Data")
check_missing_values(df_movie_budgets, "Movie Budgets Data")






# Checking for missing values
print("Missing Values:\n")
print("Movie Info:\n", df_movie_info.isnull().sum(), "\n")
print("Reviews:\n", df_reviews.isnull().sum(), "\n")


# Connect to SQLite database
db_path = "im.db"
conn = sqlite3.connect(db_path)
cursor = conn.cursor()

# Getting all table names
cursor.execute("SELECT name FROM sqlite_master WHERE type='table';")
tables = [t[0] for t in cursor.fetchall()]

# Fetching column names for a table
def get_columns(table_name):
    cursor.execute(f"PRAGMA table_info({table_name});")
    return [col[1] for col in cursor.fetchall()]

# Counting NULL values in each column of a table
def check_missing_values(table_name):
    columns = get_columns(table_name)
    if not columns:
        return None
    
    query = f"""
    SELECT 
        COUNT(*) AS total_rows, 
        {", ".join([f"SUM(CASE WHEN {col} IS NULL THEN 1 ELSE 0 END) AS missing_{col}" for col in columns])}
    FROM {table_name};
    """
    cursor.execute(query)
    return cursor.fetchall(), columns

# Checking for missing values in all tables
for table in tables:
    print(f"\n🔹 Checking missing values in {table} 🔹")
    missing_data, columns = check_missing_values(table)

    if missing_data:
        df_missing = pd.DataFrame(missing_data, columns=["total_rows"] + [f"missing_{col}" for col in columns])
        print(df_missing)
    else:
        print(f"⚠ No columns found in {table}")











df_box_office.dropna(subset=["studio", "domestic_gross"], inplace=True)





df_box_office["foreign_gross"] = df_box_office["foreign_gross"].replace(",", "", regex=True).astype(float)
df_box_office["foreign_gross"].fillna(df_box_office["foreign_gross"].median(), inplace=True)


# Checking handled missing values

# To confirm no missing values
print(df_box_office["foreign_gross"].dtype)  
print(df_box_office.isnull().sum())  


# Connect to database
db_path = "im.db"
conn = sqlite3.connect(db_path)
cursor = conn.cursor()

# Dictionary of missing value fixes
fix_queries = [
    # movie_basics
    "UPDATE movie_basics SET runtime_minutes = (SELECT ROUND(AVG(runtime_minutes), 0) FROM movie_basics WHERE runtime_minutes IS NOT NULL) WHERE runtime_minutes IS NULL;",
    "UPDATE movie_basics SET genres = 'Unknown' WHERE genres IS NULL;",
    
    # movie_akas
    "UPDATE movie_akas SET region = 'Unknown' WHERE region IS NULL;",
    "UPDATE movie_akas SET is_original_title = 0 WHERE is_original_title IS NULL;",

    # persons
    "UPDATE persons SET primary_profession = 'Unknown' WHERE primary_profession IS NULL;",

    # principals
    "UPDATE principals SET job = 'Unknown' WHERE job IS NULL;",
    "UPDATE principals SET characters = 'Not Specified' WHERE characters IS NULL;"
]

# Executing each fix
for query in fix_queries:
    cursor.execute(query)

# Committing changes 
conn.commit()

print("Missing values handled successfully!")



# Tables and columns to check for missing values
tables_to_check = {
    "movie_basics": ["runtime_minutes", "genres"],
    "movie_akas": ["region"],
    "persons": ["primary_profession"],
    "principals": ["job", "characters"]
}

# Checking for missing values
for table, columns in tables_to_check.items():
    for column in columns:
        query = f"SELECT COUNT(*) FROM {table} WHERE {column} IS NULL;"
        cursor.execute(query)
        missing_count = cursor.fetchone()[0]
        print(f"🔹 Missing values in {table}.{column}: {missing_count}")



for table in tables:
    print(f"\n🔹 Data Types in {table}:")
    cursor.execute(f"PRAGMA table_info({table});")
    columns_info = cursor.fetchall()
    for col in columns_info:
        print(f"{col[1]} - {col[2]}")  # Column Name - Data Type


# Checking if a column exists in a table
def column_exists(table_name, column_name):
    cursor.execute(f"PRAGMA table_info({table_name});")
    columns = [col[1] for col in cursor.fetchall()]
    return column_name in columns

tables_to_check = ["movie_basics", "directors", "known_for", "movie_akas", "movie_ratings", "persons", "principals", "writers"]

for table in tables_to_check:
    # Checking for movie_id
    if column_exists(table, "movie_id"):
        cursor.execute(f"SELECT movie_id FROM {table} WHERE movie_id NOT GLOB '[0-9]*' LIMIT 5;")
        non_numeric_ids = cursor.fetchall()
        print(f"🔹 Non-numeric movie_id in {table}: {non_numeric_ids}")

    # Checking for person_id
    if column_exists(table, "person_id"):
        cursor.execute


# Checking if person_id is non-numeric
for table in ["persons", "directors", "known_for", "principals", "writers"]:
    if column_exists(table, "person_id"):
        query = f"SELECT person_id FROM {table} WHERE person_id NOT GLOB 'nm[0-9]*' LIMIT 5;"
        cursor.execute(query)
        non_numeric_pids = cursor.fetchall()
        print(f"🔹 Non-numeric person_id in {table}: {non_numeric_pids}")



# Columns to check
year_columns = {
    "movie_basics": ["start_year"],
    "persons": ["birth_year", "death_year"]
}

# Checking for non-numeric values
for table, columns in year_columns.items():
    for column in columns:
        query = f"SELECT {column} FROM {table} WHERE {column} NOT GLOB '[0-9]*' LIMIT 5;"
        cursor.execute(query)
        invalid_years = cursor.fetchall()
        print(f"🔹 Non-numeric values in {table}.{column}: {invalid_years}")






#Checking for Duplicates in the DataFrame

print(f"🔍 Duplicates in Box Office Data: {df_box_office.duplicated().sum()}")
print(f"🔍 Duplicates in TMDb Movies Data: {df_tmdb_movies.duplicated().sum()}")
print(f"🔍 Duplicates in Movie Budgets Data: {df_movie_budgets.duplicated().sum()}")


 # Checking for leading/trailing spaces & inconsistent casing:
df_box_office["title"] = df_box_office["title"].str.strip().str.lower()
df_box_office["studio"] = df_box_office["studio"].str.strip().str.lower()


# Counting occurrences of each title
df_box_office["title"].value_counts().head(10)


df_box_office[df_box_office["title"] == "bluebeard"]


# Differentiating the titles Bluebeard by adding the release year
df_box_office["title"] = df_box_office["title"] + " (" + df_box_office["year"].astype(str) + ")"
df_box_office["title"].value_counts()[df_box_office["title"].value_counts() > 1]














# Merging IMDb genres with box office and budget data

df = df_movies.merge(df_box_office, left_on='primary_title', right_on='title', how='inner')
df = df.merge(df_movie_budgets, left_on='primary_title', right_on='movie', how='inner')
print(df_box_office.head())
print(df_movie_budgets.head())





# Cleaning Up df_movie_budgets to remove '$' and ',' from the budget and revenue columns before merging correctly

df_movie_budgets['domestic_gross'] = df_movie_budgets['domestic_gross'].str.replace('[$,]', '', regex=True).astype(float)
df_movie_budgets['worldwide_gross'] = df_movie_budgets['worldwide_gross'].str.replace('[$,]', '', regex=True).astype(float)
df_movie_budgets['production_budget'] = df_movie_budgets['production_budget'].str.replace('[$,]', '', regex=True).astype(float)


# Standardizing the data and removing whitspaces

df_box_office['title'] = df_box_office['title'].str.lower().str.strip()
df_movie_budgets['movie'] = df_movie_budgets['movie'].str.lower().str.strip()


# Dropping duplicates before merging
df_box_office = df_box_office.drop_duplicates(subset=['title'])
df_movie_budgets = df_movie_budgets.drop_duplicates(subset=['movie'])


# Merging df_box_office and df_movie_budgets using title and movie
import re

# Removing year from titles
def clean_title(title):
    return re.sub(r'\s*\(\d{4}\)\s*', '', title) 

# Applying function to df_box_office
df_box_office['title'] = df_box_office['title'].apply(clean_title)

# Merging
df_combined = df_box_office.merge(df_movie_budgets, left_on='title', right_on='movie', how='inner')

# Results
print(df_combined[['title', 'movie', 'domestic_gross_x', 'domestic_gross_y']].head())


# Prioritizing one column to avoid duplicate columns

df_combined['domestic_gross'] = df_combined['domestic_gross_x'].fillna(df_combined['domestic_gross_y'])
df_combined.drop(columns=['domestic_gross_x', 'domestic_gross_y'], inplace=True)
print(df_combined.isnull().sum())
print(df_combined.dtypes)


# Converting foreign_gross to numeric and sort missing values

df_combined['foreign_gross'] = (
    df_combined['foreign_gross']
    .replace(',', '', regex=True)  # Removing commas
    .apply(pd.to_numeric, errors='coerce')  # Converting to float, setting errors to NaN
    .fillna(0)  # Replacing NaNs with 0
)

# Handling missing values in studio
df_combined['studio'].fillna('Unknown', inplace=True)

print(df_combined.isnull().sum())  
print(df_combined.dtypes)





# Calculating Total Revenue (Worldwide Gross)
df_combined['total_revenue'] = df_combined['domestic_gross'] + df_combined['foreign_gross']

# Calculating Profit (Revenue - Budget)
df_combined['profit'] = df_combined['total_revenue'] - df_combined['production_budget']

# Calculating Profit Margin (%)
df_combined['profit_margin'] = (df_combined['profit'] / df_combined['production_budget']) * 100

# Display first few rows
print(df_combined[['title', 'production_budget', 'domestic_gross', 'foreign_gross', 'total_revenue', 'profit', 'profit_margin']].head())






# Sorting movies by profit in descending order
most_profitable_movies = df_combined.sort_values(by='profit', ascending=False).head(10)

# Displaying the top 10 most profitable movies
print(most_profitable_movies[['title', 'profit', 'profit_margin', 'total_revenue']])


# Sorting movies by profit in descending order
most_profitable_movies = df_combined.sort_values(by='profit', ascending=False).head(10)

# Plotting Top 10 Most Profitable Movies 
plt.figure(figsize=(12, 6))
sns.barplot(
    x='profit', 
    y='title', 
    data=most_profitable_movies, 
    palette='viridis'
)

plt.xlabel('Profit ($ Billions)')
plt.ylabel('Movie Title')
plt.title('Top 10 Most Profitable Movies')
plt.xticks(rotation=45)
plt.grid(axis='x', linestyle='--', alpha=0.5)

# Display 
plt.show()








# Sorting movies by profit in ascending order 
least_profitable_movies = df_combined.sort_values(by='profit', ascending=True).head(10)

# Plotting Top 10 least Profitable Movies
plt.figure(figsize=(12, 6))
sns.barplot(
    x='profit', 
    y='title', 
    data=least_profitable_movies, 
    palette=['red' if x < 0 else 'orange' for x in least_profitable_movies['profit']]
)

# Labels & Title
plt.xlabel('Profit ($)')
plt.ylabel('Movie Title')
plt.title('Top 10 Least Profitable Movies (Loss-Making & Low-Profit Films)')
plt.axvline(0, color='black', linestyle='--', alpha=0.8)  
plt.grid(axis='x', linestyle='--', alpha=0.5)

# Display 
plt.show()








# Merging df_movie_info with df_combined on id
df_combined = df_combined.merge(
    df_movie_info[['id', 'genre']], 
    on='id', 
    how='left'
)


# Splitting and exploding  multiple genres per movie
df_genres = df_combined.assign(genre=df_combined['genre'].str.split(', '))
df_genres = df_genres.explode('genre')

# Aggregating data per genre
genre_profitability = df_genres.groupby('genre').agg(
    total_movies=('title', 'count'),
    total_revenue=('total_revenue', 'sum'),
    total_profit=('profit', 'sum'),
    avg_profit_margin=('profit_margin', 'mean')
).reset_index()

# Sorting by total profit
genre_profitability = genre_profitability.sort_values(by='total_profit', ascending=False)

# Displaying the top 10 most profitable genres
print(genre_profitability.head(10))





# Calculating confidence Intervals for Revenue by genre
def compute_confidence_intervals(df, value_column, group_column, confidence=0.95):
    results = []

    for group, subset in df.groupby(group_column):
        data = subset[value_column].dropna()  # Removing NaNs
        if len(data) > 1:  # Ensuring there is enough data for a confidence interval
            mean = np.mean(data)
            sem = stats.sem(data)  # Standard Error of the Mean
            margin = sem * stats.t.ppf((1 + confidence) / 2., len(data) - 1)  # Margin of error
            lower = mean - margin
            upper = mean + margin
            results.append((group, mean, lower, upper))
    
    return pd.DataFrame(results, columns=[group_column, 'Mean', 'Lower CI', 'Upper CI'])

# computing confidence intervals for revenue by genre
confidence_intervals_revenue = compute_confidence_intervals(df_combined, 'worldwide_gross', 'genre')

# Results
print(confidence_intervals_revenue.head(10))








# Selecting top 10 profitable genres
top_genres = genre_profitability.head(10)

# Plotting Top 10 most profitable genre
plt.figure(figsize=(12, 6))
sns.barplot(
    data=top_genres, 
    x='total_profit', 
    y='genre', 
    palette='viridis'
)

# Labels and Title
plt.xlabel("Total Profit (in Billions)", fontsize=12)
plt.ylabel("Genre", fontsize=12)
plt.title("Top 10 Most Profitable Movie Genres", fontsize=14)
plt.xticks(rotation=45)

# Display 
plt.show()








# finding the least profitable genre

# Selecting 10 least profitable genres
least_profitable_genres = genre_profitability.tail(10)

# Plotting top 10 least profitable genre
plt.figure(figsize=(12, 6))
sns.barplot(
    data=least_profitable_genres, 
    x='total_profit', 
    y='genre', 
    palette='Reds_r'
)

# Labels and Title
plt.xlabel("Total Profit (in Billions)", fontsize=12)
plt.ylabel("Genre", fontsize=12)
plt.title("Bottom 10 Least Profitable Movie Genres", fontsize=14)
plt.xticks(rotation=45)

# Display 
plt.show()








# Ensuring only one 'genre' column exists
df_combined = df_combined.drop(columns=['genre_x'], errors='ignore').rename(columns={'genre_y': 'genre'})

# Filling missing genres with 'Unknown' or drop NaN values
df_combined['genre'] = df_combined['genre'].fillna('Unknown')

# Splitting and exploding genres for multiple assignments
df_combined['genre'] = df_combined['genre'].str.split('|')
df_genre_trends = df_combined.explode('genre')

# Display 
print(df_genre_trends[['id', 'title', 'genre']].head())


# Ensuring 'id' is of the same type in both DataFrames
df_movie_info['id'] = df_movie_info['id'].astype(str)
df_combined['id'] = df_combined['id'].astype(str)

# Merging 'genre' from df_movie_info into df_combined
df_combined = df_combined.merge(df_movie_info[['id', 'genre']], on='id', how='left')

# Handling duplicate genre columns
if 'genre_x' in df_combined.columns and 'genre_y' in df_combined.columns:
    df_combined['genre'] = df_combined['genre_y']
    df_combined.drop(columns=['genre_x', 'genre_y'], inplace=True, errors='ignore')

# Filling missing genres with 'Unknown'
df_combined['genre'].fillna('Unknown', inplace=True)

# Splitting genres into multiple rows 
df_combined['genre'] = df_combined['genre'].str.split('|')  
df_combined = df_combined.explode('genre')  

# Confirming changes
print(df_combined[['id', 'title', 'genre']].head())  


# Ensuring 'year' is numeric for proper sorting
df_combined['year'] = pd.to_numeric(df_combined['year'], errors='coerce')

# Grouping by Year & Genre to calculate total profit per genre per year
df_genre_trends = df_combined.groupby(['year', 'genre'])['profit'].sum().reset_index()

# Filtering out 'Unknown' genre for better insights
df_genre_trends = df_genre_trends[df_genre_trends['genre'] != 'Unknown']

# Plotting genre trends over time
plt.figure(figsize=(12, 6))
sns.lineplot(data=df_genre_trends, x='year', y='profit', hue='genre', marker='o')

plt.title('Genre Profitability Trends Over Time')
plt.xlabel('Year')
plt.ylabel('Total Profit (USD)')
plt.legend(title='Genre', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.grid(True)

# Display
plt.show()











import statsmodels.api as sm

# Removing outliers 
df_filtered = df_combined[(df_combined['production_budget'] > 1e6) & 
                          (df_combined['worldwide_gross'] > 1e6)]
# Plotting Scatter plot with regression line
plt.figure(figsize=(12, 6))
sns.regplot(x=df_filtered['production_budget'], 
            y=df_filtered['worldwide_gross'], 
            scatter_kws={'alpha':0.5}, 
            line_kws={"color": "red"})

plt.xscale('log')  # Log scale for better visualization
plt.yscale('log')
plt.xlabel("Production Budget (Log Scale)")
plt.ylabel("Worldwide Gross Revenue (Log Scale)")
plt.title("Relationship Between Budget & Revenue")
plt.grid(True)
plt.show()








# Defining budget ranges
bins = [0, 10e6, 50e6, 100e6, 200e6, np.inf]
labels = ['Low Budget (<$10M)', 'Medium ($10M-$50M)', 'High ($50M-$100M)', 
          'Big Budget ($100M-$200M)', 'Blockbuster (>$200M)']

df_combined['budget_category'] = pd.cut(df_combined['production_budget'], bins=bins, labels=labels)

# Calculating average ROI per budget category
df_budget_roi = df_combined.groupby('budget_category').agg(
    avg_budget=('production_budget', 'mean'),
    avg_revenue=('worldwide_gross', 'mean'),
    avg_profit=('profit', 'mean'),
    avg_roi=('profit_margin', 'mean')
).reset_index()

# Plotting ROI per budget category
plt.figure(figsize=(12, 5))
sns.barplot(data=df_budget_roi, x='budget_category', y='avg_roi', palette='viridis')

plt.title("Average ROI by Budget Range")
plt.xlabel("Budget Category")
plt.ylabel("Average ROI (%)")
plt.xticks(rotation=30)
plt.grid(True)

# Display
plt.show()








from scipy.stats import pearsonr

# Computing correlation between budget and revenue
corr, p_value = pearsonr(df_filtered['production_budget'], df_filtered['worldwide_gross'])

print(f"Pearson Correlation: {corr:.3f} (p-value: {p_value:.5f})")


# Plotting Correlation Between Budget and Revenue
plt.figure(figsize=(12,6))
sns.regplot(x=df_filtered['production_budget'], 
            y=df_filtered['worldwide_gross'], 
            scatter_kws={'alpha':0.5}, 
            line_kws={'color':'red'})

plt.xlabel("Production Budget ($M)")
plt.ylabel("Worldwide Gross Revenue ($M)")
plt.title("Correlation Between Budget and Revenue")

#Display
plt.show()











# converting  the rating column into a numeric format.
# Ensure 'rating' is a string before processing
df_reviews['rating'] = df_reviews['rating'].astype(str)

# Extract the numeric value before the slash (e.g., "3/5" → 3)
df_reviews['rating'] = df_reviews['rating'].str.extract(r'(\d+)/\d+')

# Convert to numeric (ignoring NaNs)
df_reviews['rating'] = pd.to_numeric(df_reviews['rating'], errors='coerce')


# Computing average critic rating per movie Id
df_critic_avg = df_reviews.groupby('id')['rating'].mean().reset_index()
df_critic_avg.rename(columns={'rating': 'critic_score'}, inplace=True)


# Convert 'id' to string in both DataFrames to match types
df_filtered['id'] = df_filtered['id'].astype(str)
df_critic_avg['id'] = df_critic_avg['id'].astype(str)

# Merging audience/Critic scores from different datasets
df_filtered = df_filtered.merge(df_critic_avg, on='id', how='left')
df_filtered.head()


# Computing the correlation between critic ratings and worldwide revenue

# Dropping NaNs before correlation calculation
df_corr = df_filtered.dropna(subset=['critic_score', 'worldwide_gross'])

# Computing correlation
critic_corr, critic_p = pearsonr(df_corr['critic_score'], df_corr['worldwide_gross'])

print(f"Critic Score Correlation: {critic_corr:.3f} (p-value: {critic_p:.5f})")


# Dropping NaNs before visualization
df_corr = df_filtered.dropna(subset=['critic_score', 'worldwide_gross'])

# Set figure size
plt.figure(figsize=(12, 6))

# Scatter plot with regression line
sns.regplot(x=df_corr['critic_score'], y=df_corr['worldwide_gross'], scatter_kws={'alpha': 0.5}, line_kws={'color': 'red'})

# Titles and labels
plt.title("Correlation Between Critic Scores and Worldwide Revenue", fontsize=14)
plt.xlabel("Critic Score", fontsize=12)
plt.ylabel("Worldwide Gross Revenue ($)", fontsize=12)
plt.grid(True)

# Display
plt.show()








# creating a new column 'release_month' from the release_date column

# Ensuring release_date is in datetime format
df_filtered['release_date'] = pd.to_datetime(df_filtered['release_date'], errors='coerce')

# Extracting month
df_filtered['release_month'] = df_filtered['release_date'].dt.month
df_filtered['release_month'].head()


# Calculating the average worldwide gross revenue per month

# Grouping by release month and computing average worldwide gross revenue
monthly_revenue = df_filtered.groupby('release_month')['worldwide_gross'].mean().reset_index()

# Sorting by highest earnings
monthly_revenue = monthly_revenue.sort_values(by='worldwide_gross', ascending=False)

print(monthly_revenue)


# Plotting average worldwide gross revenue per month
plt.figure(figsize=(12, 6))

# Bar plot
sns.barplot(x=monthly_revenue['release_month'], y=monthly_revenue['worldwide_gross'], palette="coolwarm")

# Titles and labels
plt.title("Average Worldwide Gross Revenue by Release Month", fontsize=14)
plt.xlabel("Release Month", fontsize=12)
plt.ylabel("Average Worldwide Gross Revenue ($)", fontsize=12)
plt.xticks(ticks=range(12), labels=['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])
plt.grid(axis='y', linestyle='--', alpha=0.7)

# Display
plt.show()








# Converting budget and revenue columns to numeric
df_movie_budgets['production_budget'] = df_movie_budgets['production_budget'].replace('[\$,]', '', regex=True).astype(float)
df_movie_budgets['worldwide_gross'] = df_movie_budgets['worldwide_gross'].replace('[\$,]', '', regex=True).astype(float)

# Dropping missing values
df_cleaned = df_movie_budgets.dropna(subset=['production_budget', 'worldwide_gross'])

# summary statistics
print(df_cleaned[['production_budget', 'worldwide_gross']].describe())


# Computing Pearson correlation
corr, p_value = pearsonr(df_cleaned['production_budget'], df_cleaned['worldwide_gross'])

# Display
print(f"Correlation Coefficient: {corr:.3f}")
print(f"P-value: {p_value:.5f}")

# Interpretation:
# - If corr is close to +1, strong positive correlation (higher marketing spend → higher revenue)
# - If corr is close to 0, no significant correlation
# - If p-value < 0.05, correlation is statistically significant





# Plotting Impact of Marketing Spend on Box Office Revenue
plt.figure(figsize=(10, 6))
sns.regplot(x='production_budget', y='worldwide_gross', data=df_cleaned, scatter_kws={'alpha':0.5}, line_kws={'color':'red'})
plt.xlabel("Production Budget ($)")
plt.ylabel("Worldwide Gross Revenue ($)")
plt.title("Marketing Spend vs. Box Office Revenue")
plt.show()





















